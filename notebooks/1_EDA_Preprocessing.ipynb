{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "# 1_EDA_Preprocessing.ipynb\n",
        "\n",
        "Ce notebook est dédié à l'exploration des données (EDA) et au prétraitement pour le projet DeepRec.\n",
        "Nous allons charger le jeu de données MovieLens, l'inspecter, effectuer une analyse exploratoire\n",
        "et préparer les données pour l'entraînement des modèles de recommandation.\n",
        "\"\"\"\n",
        "\n",
        "# 1. Importation des bibliothèques nécessaires\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(\"Bibliothèques importées avec succès.\")\n",
        "\n",
        "# 2. Chargement du jeu de données MovieLens\n",
        "\n",
        "try:\n",
        "    # Chemin vers le fichier de ratings\n",
        "    ratings_path = '../data/ratings.csv'\n",
        "    # Charger les données de ratings\n",
        "    # Les colonnes typiques sont 'userId', 'movieId', 'rating', 'timestamp'\n",
        "    df_ratings = pd.read_csv(ratings_path)\n",
        "    print(f\"Jeu de données chargé depuis : {ratings_path}\")\n",
        "    print(f\"Nombre d'enregistrements : {len(df_ratings)}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Erreur : Le fichier {ratings_path} n'a pas été trouvé.\")\n",
        "    print(\"Veuillez vous assurer que le fichier 'ratings.csv' est dans le dossier 'data/'.\")\n",
        "    print(\"Tu peux télécharger le jeu de données MovieLens ici : https://grouplens.org/datasets/movielens/\")\n",
        "    exit() # Quitte le script si le fichier n'est pas trouvé\n",
        "\n",
        "# 3. Inspection initiale des données\n",
        "print(\"\\n--- Aperçu des 5 premières lignes du DataFrame ---\")\n",
        "print(df_ratings.head())\n",
        "\n",
        "print(\"\\n--- Informations sur le DataFrame ---\")\n",
        "print(df_ratings.info())\n",
        "\n",
        "print(\"\\n--- Statistiques descriptives du DataFrame ---\")\n",
        "print(df_ratings.describe())\n",
        "\n",
        "# Vérifier les valeurs manquantes\n",
        "print(\"\\n--- Vérification des valeurs manquantes ---\")\n",
        "print(df_ratings.isnull().sum())\n",
        "\n",
        "# Pour MovieLens, il est rare d'avoir des valeurs manquantes dans les colonnes principales.\n",
        "# Si d'autres datasets sont utilisés, cette étape est cruciale pour décider\n",
        "# de l'imputation ou de la suppression.\n",
        "\n",
        "# 4. Analyse Exploratoire des Données (EDA)\n",
        "\n",
        "# Nombre d'utilisateurs et de films uniques\n",
        "n_users = df_ratings['userId'].nunique()\n",
        "n_movies = df_ratings['movieId'].nunique()\n",
        "print(f\"\\nNombre d'utilisateurs uniques : {n_users}\")\n",
        "print(f\"Nombre de films uniques : {n_movies}\")\n",
        "\n",
        "# Distribution des notes\n",
        "print(\"\\n--- Distribution des notes ---\")\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.countplot(x='rating', data=df_ratings, palette='viridis')\n",
        "plt.title('Distribution des notes')\n",
        "plt.xlabel('Note')\n",
        "plt.ylabel('Nombre d\\'enregistrements')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "\n",
        "# Films les plus notés (par nombre de notes)\n",
        "print(\"\\n--- Top 10 des films les plus notés (par nombre d'évaluations) ---\")\n",
        "top_rated_movies = df_ratings['movieId'].value_counts().head(10)\n",
        "print(top_rated_movies)\n",
        "\n",
        "# Utilisateurs les plus actifs (par nombre de notes)\n",
        "print(\"\\n--- Top 10 des utilisateurs les plus actifs (par nombre d'évaluations) ---\")\n",
        "most_active_users = df_ratings['userId'].value_counts().head(10)\n",
        "print(most_active_users)\n",
        "\n",
        "# Matrice de ratings (peut être très sparse)\n",
        "# Il est important de comprendre la sparsité de la matrice.\n",
        "# La sparsité est le pourcentage de valeurs manquantes (non notées) dans la matrice utilisateur-film.\n",
        "total_possible_ratings = n_users * n_movies\n",
        "actual_ratings = len(df_ratings)\n",
        "sparsity = (1 - actual_ratings / total_possible_ratings) * 100\n",
        "print(f\"\\nSparsité de la matrice utilisateur-film : {sparsity:.2f}%\")\n",
        "\n",
        "# 5. Prétraitement des données pour les modèles\n",
        "# Créer des IDs numériques séquentiels pour les utilisateurs et les films\n",
        "# C'est important car les IDs originaux peuvent ne pas être séquentiels et peuvent être très grands.\n",
        "# Les modèles de Deep Learning (embeddings) ont besoin d'IDs séquentiels et commençant à 0.\n",
        "\n",
        "# Mapping des IDs d'utilisateurs\n",
        "unique_users = df_ratings['userId'].unique()\n",
        "user_to_id = {user: i for i, user in enumerate(unique_users)}\n",
        "id_to_user = {i: user for user, i in user_to_id.items()}\n",
        "df_ratings['user_id_mapped'] = df_ratings['userId'].map(user_to_id)\n",
        "\n",
        "# Mapping des IDs de films\n",
        "unique_movies = df_ratings['movieId'].unique()\n",
        "movie_to_id = {movie: i for i, movie in enumerate(unique_movies)}\n",
        "id_to_movie = {i: movie for movie, i in movie_to_id.items()}\n",
        "df_ratings['movie_id_mapped'] = df_ratings['movieId'].map(movie_to_id)\n",
        "\n",
        "print(\"\\n--- Aperçu du DataFrame avec les IDs mappés ---\")\n",
        "print(df_ratings.head())\n",
        "\n",
        "# Sauvegarder les mappings pour une utilisation future (par exemple, pour afficher les noms de films réels)\n",
        "# Il est crucial de les sauvegarder pour pouvoir \"dé-mapper\" les prédictions.\n",
        "np.save('../data/user_to_id.npy', user_to_id)\n",
        "np.save('../data/id_to_user.npy', id_to_user)\n",
        "np.save('../data/movie_to_id.npy', movie_to_id)\n",
        "np.save('../data/id_to_movie.npy', id_to_movie)\n",
        "print(\"\\nMappings d'IDs sauvegardés dans le dossier 'data/'.\")\n",
        "\n",
        "# 6. Division des données en ensembles d'entraînement, de validation et de test\n",
        "# Nous allons diviser les données en 80% entraînement, 10% validation, 10% test.\n",
        "# La validation est utilisée pour l'ajustement des hyperparamètres pendant l'entraînement.\n",
        "\n",
        "# D'abord, diviser en entraînement + validation et test\n",
        "train_val_df, test_df = train_test_split(\n",
        "    df_ratings,\n",
        "    test_size=0.1, # 10% pour le test\n",
        "    random_state=42, # Pour la reproductibilité\n",
        "    stratify=df_ratings['userId'] # Stratifier par utilisateur pour s'assurer que chaque utilisateur est représenté dans les deux ensembles\n",
        ")\n",
        "\n",
        "# Ensuite, diviser l'ensemble entraînement + validation en entraînement et validation\n",
        "train_df, val_df = train_test_split(\n",
        "    train_val_df,\n",
        "    test_size=(0.1 / 0.9), # 10% de l'original / (1 - 10% test) = 10% / 90%\n",
        "    random_state=42,\n",
        "    stratify=train_val_df['userId']\n",
        ")\n",
        "\n",
        "print(f\"\\nDimensions de l'ensemble d'entraînement : {train_df.shape}\")\n",
        "print(f\"Dimensions de l'ensemble de validation : {val_df.shape}\")\n",
        "print(f\"Dimensions de l'ensemble de test : {test_df.shape}\")\n",
        "\n",
        "# Sauvegarder les ensembles de données prétraitées\n",
        "train_df.to_csv('../data/train_ratings.csv', index=False)\n",
        "val_df.to_csv('../data/val_ratings.csv', index=False)\n",
        "test_df.to_csv('../data/test_ratings.csv', index=False)\n",
        "print(\"\\nEnsembles de données (entraînement, validation, test) sauvegardés dans le dossier 'data/'.\")\n",
        "\n",
        "print(\"\\n--- Prétraitement des données terminé avec succès ! ---\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "clZUobVLADFZ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
