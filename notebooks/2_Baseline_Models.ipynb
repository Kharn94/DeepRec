{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "# 2_Baseline_Models.ipynb\n",
        "\n",
        "Ce notebook implémente et évalue des modèles de recommandation de base :\n",
        "le filtrage collaboratif (basé sur la similarité) et la factorisation matricielle (SVD).\n",
        "Ces modèles serviront de points de comparaison pour le modèle de Deep Learning.\n",
        "\"\"\"\n",
        "\n",
        "# 1. Importation des bibliothèques nécessaires\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Pour le filtrage collaboratif basé sur la similarité\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Pour la factorisation matricielle (SVD)\n",
        "# La bibliothèque Surprise est excellente pour les systèmes de recommandation.\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import train_test_split as surprise_train_test_split\n",
        "from surprise import accuracy\n",
        "\n",
        "print(\"Bibliothèques importées avec succès.\")\n",
        "\n",
        "# 2. Chargement des données prétraitées et des mappings\n",
        "try:\n",
        "    train_df = pd.read_csv('../data/train_ratings.csv')\n",
        "    val_df = pd.read_csv('../data/val_ratings.csv')\n",
        "    test_df = pd.read_csv('../data/test_ratings.csv')\n",
        "\n",
        "    user_to_id = np.load('../data/user_to_id.npy', allow_pickle=True).item()\n",
        "    id_to_user = np.load('../data/id_to_user.npy', allow_pickle=True).item()\n",
        "    movie_to_id = np.load('../data/movie_to_id.npy', allow_pickle=True).item()\n",
        "    id_to_movie = np.load('../data/id_to_movie.npy', allow_pickle=True).item()\n",
        "\n",
        "    print(\"Données d'entraînement, de validation, de test et mappings chargés avec succès.\")\n",
        "    print(f\"Train DataFrame shape: {train_df.shape}\")\n",
        "    print(f\"Validation DataFrame shape: {val_df.shape}\")\n",
        "    print(f\"Test DataFrame shape: {test_df.shape}\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Erreur : Les fichiers de données ou de mappings n'ont pas été trouvés.\")\n",
        "    print(\"Assure-toi d'avoir exécuté le notebook '1_EDA_Preprocessing.ipynb' au préalable.\")\n",
        "    exit()\n",
        "\n",
        "# Déterminer le nombre total d'utilisateurs et de films mappés\n",
        "n_users_mapped = len(user_to_id)\n",
        "n_movies_mapped = len(movie_to_id)\n",
        "print(f\"Nombre d'utilisateurs mappés : {n_users_mapped}\")\n",
        "print(f\"Nombre de films mappés : {n_movies_mapped}\")\n",
        "\n",
        "# --- Modèle 1 : Filtrage Collaboratif Basé sur la Similarité (Simple) ---\n",
        "print(\"\\n--- Modèle 1 : Filtrage Collaboratif Basé sur la Similarité ---\")\n",
        "\n",
        "# Pour une implémentation simple, nous allons créer une matrice utilisateur-film\n",
        "# à partir de l'ensemble d'entraînement.\n",
        "# Note : Cette approche peut être très gourmande en mémoire pour de grands datasets.\n",
        "# Pour des datasets plus grands, il est préférable d'utiliser des approches basées sur la sparsité.\n",
        "\n",
        "# Créer une matrice pivot (utilisateur x film) à partir du DataFrame d'entraînement\n",
        "# Remplir les valeurs manquantes avec NaN\n",
        "user_movie_matrix = train_df.pivot(index='user_id_mapped', columns='movie_id_mapped', values='rating')\n",
        "print(\"\\nAperçu de la matrice utilisateur-film (sparse) :\")\n",
        "print(user_movie_matrix.head())\n",
        "\n",
        "# Calcul de la similarité entre utilisateurs (basée sur les notes communes)\n",
        "# Remplir les NaN avec 0 pour le calcul de similarité (ou une autre stratégie)\n",
        "# Attention : Remplir avec 0 peut fausser la similarité si 0 est une note possible.\n",
        "# Pour la similarité cosinus, il est souvent préférable de ne considérer que les éléments notés en commun.\n",
        "# Pour simplifier ici, nous allons utiliser une approche directe sur la matrice remplie.\n",
        "user_movie_matrix_filled = user_movie_matrix.fillna(0)\n",
        "user_similarity = cosine_similarity(user_movie_matrix_filled)\n",
        "user_similarity_df = pd.DataFrame(user_similarity, index=user_movie_matrix.index, columns=user_movie_matrix.index)\n",
        "print(\"\\nAperçu de la matrice de similarité utilisateur :\")\n",
        "print(user_similarity_df.head())\n",
        "\n",
        "# Fonction de prédiction simple pour le filtrage collaboratif basé sur l'utilisateur\n",
        "def predict_user_based_cf(user_id, movie_id, user_movie_matrix, user_similarity_df, k=10):\n",
        "    \"\"\"\n",
        "    Prédit la note d'un film pour un utilisateur donné en utilisant le filtrage collaboratif basé sur l'utilisateur.\n",
        "    Args:\n",
        "        user_id (int): ID mappé de l'utilisateur.\n",
        "        movie_id (int): ID mappé du film.\n",
        "        user_movie_matrix (pd.DataFrame): Matrice utilisateur-film.\n",
        "        user_similarity_df (pd.DataFrame): Matrice de similarité utilisateur.\n",
        "        k (int): Nombre de voisins les plus proches à considérer.\n",
        "    Returns:\n",
        "        float: Prédiction de la note.\n",
        "    \"\"\"\n",
        "    if movie_id not in user_movie_matrix.columns:\n",
        "        return user_movie_matrix.mean().mean() # Retourne la moyenne générale si le film est inconnu\n",
        "\n",
        "    # Trouver les utilisateurs similaires qui ont noté le film\n",
        "    similar_users = user_similarity_df[user_id].drop(user_id).sort_values(ascending=False)\n",
        "\n",
        "    # Filtrer les utilisateurs qui ont noté le film en question\n",
        "    rated_by_similar = user_movie_matrix[movie_id].dropna()\n",
        "\n",
        "    # Trouver les k voisins les plus proches qui ont noté le film\n",
        "    # On prend les 'k' utilisateurs les plus similaires qui ont effectivement noté le film\n",
        "    neighbors = similar_users.index.intersection(rated_by_similar.index)\n",
        "    top_k_neighbors = similar_users[neighbors].head(k).index\n",
        "\n",
        "    if not top_k_neighbors.empty:\n",
        "        # Calcul de la moyenne pondérée des notes des voisins\n",
        "        # Poids = similarité, Valeur = note du film par le voisin\n",
        "        numerator = sum(user_similarity_df.loc[user, user_id] * user_movie_matrix.loc[user, movie_id]\n",
        "                        for user in top_k_neighbors)\n",
        "        denominator = sum(abs(user_similarity_df.loc[user, user_id]) for user in top_k_neighbors)\n",
        "\n",
        "        if denominator == 0:\n",
        "            return user_movie_matrix.loc[user_id].mean() if user_id in user_movie_matrix.index else user_movie_matrix.mean().mean()\n",
        "\n",
        "        prediction = numerator / denominator\n",
        "        # S'assurer que la prédiction est dans la plage des notes (1 à 5)\n",
        "        return max(1.0, min(5.0, prediction))\n",
        "    else:\n",
        "        # Si aucun voisin n'a noté le film, retourner la moyenne de l'utilisateur ou la moyenne générale\n",
        "        return user_movie_matrix.loc[user_id].mean() if user_id in user_movie_matrix.index else user_movie_matrix.mean().mean()\n",
        "\n",
        "# Évaluation du modèle de filtrage collaboratif sur l'ensemble de test\n",
        "print(\"\\nÉvaluation du Filtrage Collaboratif Basé sur la Similarité (sur l'ensemble de test)...\")\n",
        "predictions_cf = []\n",
        "true_ratings_cf = []\n",
        "\n",
        "# Pour des raisons de performance, évaluer sur un sous-ensemble du test_df si test_df est très grand\n",
        "# Ou optimiser la fonction de prédiction pour des calculs par lots.\n",
        "# Ici, nous allons itérer, ce qui peut être lent pour de grands datasets.\n",
        "# Limiter à 1000 prédictions pour l'exemple si le dataset est grand.\n",
        "sample_test_df = test_df.sample(n=min(len(test_df), 5000), random_state=42) # Limiter à 5000 échantillons\n",
        "\n",
        "for index, row in sample_test_df.iterrows():\n",
        "    user_id = row['user_id_mapped']\n",
        "    movie_id = row['movie_id_mapped']\n",
        "    true_rating = row['rating']\n",
        "\n",
        "    predicted_rating = predict_user_based_cf(user_id, movie_id, user_movie_matrix, user_similarity_df)\n",
        "    predictions_cf.append(predicted_rating)\n",
        "    true_ratings_cf.append(true_rating)\n",
        "\n",
        "# Calcul des métriques\n",
        "rmse_cf = sqrt(mean_squared_error(true_ratings_cf, predictions_cf))\n",
        "mae_cf = mean_absolute_error(true_ratings_cf, predictions_cf)\n",
        "\n",
        "print(f\"RMSE (Filtrage Collaboratif) : {rmse_cf:.4f}\")\n",
        "print(f\"MAE (Filtrage Collaboratif) : {mae_cf:.4f}\")\n",
        "\n",
        "\n",
        "# --- Modèle 2 : Factorisation Matricielle (SVD) avec Surprise ---\n",
        "print(\"\\n--- Modèle 2 : Factorisation Matricielle (SVD) avec Surprise ---\")\n",
        "\n",
        "# Charger les données dans le format attendu par Surprise\n",
        "# Le Reader spécifie la plage des notes\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(df_ratings[['userId', 'movieId', 'rating']], reader)\n",
        "\n",
        "# Diviser les données en entraînement et test pour Surprise\n",
        "# Surprise a sa propre fonction de split qui est plus adaptée à ses objets Dataset.\n",
        "# Nous allons utiliser l'ensemble d'entraînement complet pour entraîner le modèle SVD\n",
        "# et l'évaluer sur l'ensemble de test que nous avons déjà préparé.\n",
        "# Pour Surprise, il est plus simple de recharger les données et de faire un split interne.\n",
        "# Ou alors, on peut construire un Dataset à partir de nos train_df et test_df.\n",
        "\n",
        "# Créer un Dataset Surprise à partir de train_df\n",
        "trainset = Dataset.load_from_df(train_df[['userId', 'movieId', 'rating']], reader).build_full_trainset()\n",
        "\n",
        "# Créer un testset Surprise à partir de test_df\n",
        "# Le format de testset pour Surprise est une liste de tuples (userId, movieId, true_rating)\n",
        "testset = list(test_df.apply(lambda x: (x['userId'], x['movieId'], x['rating']), axis=1))\n",
        "\n",
        "print(f\"Taille du trainset Surprise : {trainset.n_ratings} ratings\")\n",
        "print(f\"Taille du testset Surprise : {len(testset)} ratings\")\n",
        "\n",
        "# Entraînement du modèle SVD\n",
        "# On peut ajuster les paramètres comme n_factors (nombre de facteurs latents), n_epochs, lr_all, reg_all\n",
        "print(\"Entraînement du modèle SVD...\")\n",
        "algo_svd = SVD(n_factors=50, n_epochs=20, random_state=42, verbose=True)\n",
        "algo_svd.fit(trainset)\n",
        "print(\"Modèle SVD entraîné avec succès.\")\n",
        "\n",
        "# Évaluation du modèle SVD sur l'ensemble de test\n",
        "print(\"\\nÉvaluation du modèle SVD (sur l'ensemble de test)...\")\n",
        "predictions_svd = algo_svd.test(testset)\n",
        "\n",
        "# Calcul des métriques avec Surprise\n",
        "rmse_svd = accuracy.rmse(predictions_svd, verbose=False)\n",
        "mae_svd = accuracy.mae(predictions_svd, verbose=False)\n",
        "\n",
        "print(f\"RMSE (SVD) : {rmse_svd:.4f}\")\n",
        "print(f\"MAE (SVD) : {mae_svd:.4f}\")\n",
        "\n",
        "# --- Comparaison des Modèles ---\n",
        "print(\"\\n--- Comparaison des performances des modèles de base ---\")\n",
        "results = pd.DataFrame({\n",
        "    'Modèle': ['Filtrage Collaboratif', 'SVD'],\n",
        "    'RMSE': [rmse_cf, rmse_svd],\n",
        "    'MAE': [mae_cf, mae_svd]\n",
        "})\n",
        "print(results)\n",
        "\n",
        "# Visualisation de la comparaison\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Modèle', y='RMSE', data=results, palette='coolwarm')\n",
        "plt.title('Comparaison des RMSE des modèles de base')\n",
        "plt.ylabel('RMSE')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Modèle', y='MAE', data=results, palette='coolwarm')\n",
        "plt.title('Comparaison des MAE des modèles de base')\n",
        "plt.ylabel('MAE')\n",
        "plt.show()\n",
        "\n",
        "# --- Sauvegarde du modèle SVD entraîné ---\n",
        "# Il est bon de sauvegarder les modèles entraînés pour les réutiliser sans ré-entraîner.\n",
        "from surprise import dump\n",
        "dump.dump('../data/svd_model.pkl', algo=algo_svd)\n",
        "print(\"\\nModèle SVD sauvegardé sous '../data/svd_model.pkl'.\")\n",
        "\n",
        "print(\"\\n--- Implémentation et évaluation des modèles de base terminées ! ---\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "pgavhxo8E2OQ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}